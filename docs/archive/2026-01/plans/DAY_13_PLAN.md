# Day 13 Plan: Consistency, Correctness & Completeness
## 2026-01-27 (Week 2 Day 13)

## Executive Summary

**Status:** Day 12 complete - Test infrastructure built, all 55 primitives verified
**Today's Goal:** Systematic audit for consistency, correctness, and completeness
**Duration:** ~3-4 hours
**Outcome:** Production-ready foundation for Week 3 (Pattern Matching)

---

## Context: Where We Are

### âœ… What's Working (Day 12 Complete)

**Infrastructure:**
- Complete test runner (test_runner.scm - 233 lines)
- All 55 functional primitives organized by category
- 243+ manual tests passing
- 110+ auto-generated test specifications
- Coverage verification tool

**Architecture:**
- Tests-as-data design validated (correct by design!)
- Reference counting solid
- Memory management clean
- Type registry functional

### âš ï¸ Critical Discovery (Day 12)

**Tests are DATA, not executable code:**

```scheme
(âŒ‚âŠ¨ (âŒœ âŠ•))
; Returns: âŸ¨(âŠ¨ :test-normal-case #t (â„•? (âŠ• #5 #3)))
;            (âŠ¨ :test-zero-operand #t (â„•? (âŠ• #0 #5)))âŸ©
; These are QUOTED EXPRESSIONS - data structures describing tests
```

**Why this is CORRECT:**
- Tests are first-class values (can inspect, transform, reason about)
- Requires âŒ (eval) to execute (currently placeholder)
- Manual verification works now
- Future: Full automation with eval

**Current Limitation:**
- test_runner.scm tries to execute quoted tests (doesn't work)
- Need either: (1) Manual verification guide, or (2) Implement âŒ eval

---

## Three-Phase Audit Strategy

### Phase 1: Consistency Audit (1 hour)
Ensure all primitives follow same patterns

### Phase 2: Correctness Audit (1 hour)
Verify implementations match specifications

### Phase 3: Completeness Audit (1.5 hours)
Fill gaps and prepare for next phase

---

## Phase 1: Consistency Audit ğŸ”

### 1.1 Primitive Consistency Check

**Goal:** All 55 functional primitives should have consistent:
- Error handling (using âš )
- Type checking
- Reference counting
- Documentation format

**Categories to audit:**
- âœ… Arithmetic (9): âŠ• âŠ– âŠ— âŠ˜ % < > â‰¤ â‰¥
- âœ… Logic (5): â‰¡ â‰¢ âˆ§ âˆ¨ Â¬
- âœ… Type predicates (6): â„•? ğ”¹? :? âˆ…? âŸ¨âŸ©? #?
- âœ… Lists (3): âŸ¨âŸ© â— â–·
- âœ… Debug/Error (4): âš  âš ? âŠ¢ âŸ²
- âš ï¸ Testing (2): â‰Ÿ âŠ¨
- âš ï¸ Documentation (5): âŒ‚ âŒ‚âˆˆ âŒ‚â‰” âŒ‚âŠ› âŒ‚âŠ¨
- âš ï¸ CFG/DFG (2): âŒ‚âŸ¿ âŒ‚â‡
- âš ï¸ Structures (15): All âŠ™/âŠš/âŠ primitives

**Action Items:**

1. **Review error handling patterns**
   ```bash
   cd bootstrap/bootstrap
   grep -n "cell_error" primitives.c | head -20
   ```

2. **Check type validation consistency**
   ```bash
   grep -n "TYPE_" primitives.c | head -30
   ```

3. **Verify reference counting**
   ```bash
   grep -n "cell_retain\|cell_release" primitives.c | wc -l
   ```

4. **Document findings:**
   - Create CONSISTENCY_AUDIT.md
   - List any inconsistencies
   - Prioritize fixes

### 1.2 Documentation Consistency

**Check:**
- All primitives have âŒ‚ descriptions?
- All primitives have âŒ‚âˆˆ type signatures?
- All primitives have âŒ‚â‰” dependencies?
- Format is consistent?

**Test:**
```bash
cd bootstrap/bootstrap
./guage << 'EOF'
(âŒ‚ (âŒœ âŠ•))
(âŒ‚âˆˆ (âŒœ âŠ•))
(âŒ‚â‰” (âŒœ âŠ•))
EOF
```

### 1.3 Test Structure Consistency

**Check:**
- All auto-generated tests follow same structure?
- All use âŠ¨ primitive correctly?
- All test names are descriptive?

**Action:**
```bash
cd bootstrap/bootstrap
./guage < tests/test_runner.scm 2>&1 | head -100
```

---

## Phase 2: Correctness Audit âœ…

### 2.1 Primitive Correctness

**Goal:** Verify each primitive does what it claims

**Test Strategy:**

1. **Arithmetic primitives** (9)
   ```scheme
   (âŠ• #5 #3)        ; â†’ #8 âœ…
   (âŠ– #10 #3)       ; â†’ #7 âœ…
   (âŠ— #4 #5)        ; â†’ #20 âœ…
   (âŠ˜ #10 #3)       ; â†’ #3.333... âœ…
   (% #10 #3)       ; â†’ #1 âœ…
   (< #3 #5)        ; â†’ #t âœ…
   (> #5 #3)        ; â†’ #t âœ…
   (â‰¤ #3 #3)        ; â†’ #t âœ…
   (â‰¥ #5 #3)        ; â†’ #t âœ…
   ```

2. **Logic primitives** (5)
   ```scheme
   (â‰¡ #5 #5)        ; â†’ #t âœ…
   (â‰¢ #5 #3)        ; â†’ #t âœ…
   (âˆ§ #t #t)        ; â†’ #t âœ…
   (âˆ¨ #f #t)        ; â†’ #t âœ…
   (Â¬ #f)           ; â†’ #t âœ…
   ```

3. **Type predicates** (6)
   ```scheme
   (â„•? #5)          ; â†’ #t âœ…
   (ğ”¹? #t)          ; â†’ #t âœ…
   (:? :symbol)     ; â†’ #t âœ…
   (âˆ…? âˆ…)           ; â†’ #t âœ…
   (âŸ¨âŸ©? (âŸ¨âŸ© #1 #2)) ; â†’ #t âœ…
   (#? #5)          ; â†’ #t âœ…
   ```

4. **Lists** (3)
   ```scheme
   (â‰” pair (âŸ¨âŸ© #1 #2))
   (â— pair)         ; â†’ #1 âœ…
   (â–· pair)         ; â†’ #2 âœ…
   ```

5. **Debug/Error** (4)
   ```scheme
   (â‰” err (âš  :test-error #42))
   (âš ? err)         ; â†’ #t âœ…
   (âŠ¢ #t :ok)       ; â†’ #t âœ…
   (âŠ¢ #f :fail)     ; â†’ (âš  :assertion-failed :fail) âœ…
   (âŸ² #42)          ; â†’ #42 (and prints) âœ…
   ```

6. **Testing primitives** (2)
   ```scheme
   (â‰Ÿ #5 #5)        ; â†’ #t âœ…
   (â‰Ÿ (âŸ¨âŸ© #1 #2) (âŸ¨âŸ© #1 #2)) ; â†’ #t âœ…
   (âŠ¨ :test1 #t #t) ; â†’ #t âœ…
   (âŠ¨ :test2 #t #f) ; â†’ (âš  :test-failed ...) âœ…
   ```

7. **Documentation primitives** (5)
   ```scheme
   (âŒ‚ (âŒœ âŠ•))        ; â†’ ":add two numbers" âœ…
   (âŒ‚âˆˆ (âŒœ âŠ•))       ; â†’ ":â„• â†’ â„• â†’ â„•" âœ…
   (âŒ‚â‰” (âŒœ âŠ•))       ; â†’ âŸ¨...deps...âŸ© âœ…
   (âŒ‚âŠ› (âŒœ âŠ•))       ; â†’ source code âœ…
   (âŒ‚âŠ¨ (âŒœ âŠ•))       ; â†’ âŸ¨...tests...âŸ© âœ…
   ```

8. **CFG/DFG primitives** (2)
   ```scheme
   (âŒ‚âŸ¿ (âŒœ !))       ; â†’ CFG structure âœ…
   (âŒ‚â‡ (âŒœ !))       ; â†’ DFG structure âœ…
   ```

9. **Structure primitives** (15)
   ```scheme
   ; Leaf structures
   (âŠ™â‰” :Point :x :y)
   (â‰” p (âŠ™ :Point #3 #4))
   (âŠ™â†’ p :x)        ; â†’ #3 âœ…
   (âŠ™â† p :x #5)     ; â†’ new point with x=#5 âœ…
   (âŠ™? p :Point)    ; â†’ #t âœ…

   ; Node structures (ADT)
   (âŠšâ‰” :List [:Nil] [:Cons :head :tail])
   (â‰” empty (âŠš :List :Nil))
   (â‰” lst (âŠš :List :Cons #1 empty))
   (âŠšâ†’ lst :head)   ; â†’ #1 âœ…
   (âŠš? lst :List :Cons) ; â†’ #t âœ…

   ; Graph structures
   (âŠâ‰” :Graph :MyGraph :nodes :edges)
   (â‰” g (âŠ :Graph :MyGraph))
   (â‰” g2 (âŠâŠ• g #node1))
   (â‰” g3 (âŠâŠ— g2 #1 #2 :edge-label))
   (âŠâ†’ g3 :nodes)   ; â†’ list of nodes âœ…
   (âŠ? g3 :Graph)   ; â†’ #t âœ…
   ```

**Action:**
Create comprehensive_correctness.test with all above checks

### 2.2 Edge Cases

**Test edge cases for each category:**

1. **Arithmetic edges:**
   - Division by zero: `(âŠ˜ #5 #0)` â†’ error
   - Modulo by zero: `(% #5 #0)` â†’ error
   - Negative results: `(âŠ– #3 #5)` â†’ ?
   - Large numbers: `(âŠ— #999999 #999999)` â†’ ?

2. **List edges:**
   - Empty list operations: `(â— âˆ…)` â†’ error
   - Nested lists: `(âŸ¨âŸ© (âŸ¨âŸ© #1 #2) (âŸ¨âŸ© #3 #4))`
   - Deep nesting: 100-deep list

3. **Structure edges:**
   - Unknown field: `(âŠ™â†’ p :unknown)` â†’ error
   - Wrong type: `(âŠ™? #5 :Point)` â†’ #f
   - Circular references: handled?

4. **Error edges:**
   - Double errors: `(âš  :err1 (âš  :err2 #5))`
   - Error propagation in expressions

**Action:**
Create edge_cases.test with failure scenarios

### 2.3 Memory Correctness

**Verify no leaks or crashes:**

```bash
# Run all tests under memory checking
cd bootstrap/bootstrap
for test in tests/*.test; do
    echo "Testing $test..."
    ./guage < "$test" > /dev/null 2>&1 || echo "FAILED: $test"
done
```

---

## Phase 3: Completeness Audit ğŸ“‹

### 3.1 Missing Functionality

**Review SPEC.md vs Implementation:**

**Currently MISSING:**
- âŒ (eval) - CRITICAL for test automation
- Pattern matching (âˆ‡, â‰—, _) - Next major feature
- Macro system (â§‰, â§ˆ, `, ,, ,@)
- Generic programming (âŠ³, âŠ², âŠ§)

**Prioritized by Impact:**

1. **âŒ (eval) - HIGH PRIORITY** âš¡
   - Enables automatic test execution
   - Required for metaprogramming
   - Foundation for REPL improvements
   - **Estimate:** 2-3 days

2. **Pattern Matching - WEEK 3 GOAL** ğŸ¯
   - Game changer for usability
   - Required for many stdlib functions
   - **Estimate:** 1-2 weeks

3. **Standard Library - ONGOING**
   - map, filter, fold
   - list utilities
   - math functions
   - **Estimate:** Incremental

### 3.2 Documentation Completeness

**Check all docs are up to date:**

- [ ] SESSION_HANDOFF.md - Day 13 summary
- [ ] SPEC.md - Accurate primitive count
- [ ] CLAUDE.md - Reflects current state
- [ ] IMPLEMENTATION_STATUS.md - Updated checklist
- [ ] README.md - Getting started guide

**Action:**
Update each file with Day 13 changes

### 3.3 Test Coverage Completeness

**Current coverage:**
- 243+ manual tests âœ…
- 110+ auto-generated test specs âœ…
- Edge cases? âš ï¸
- Integration tests? âš ï¸
- Performance tests? âŒ

**Add:**

1. **Edge case tests**
   - Error conditions
   - Boundary values
   - Invalid inputs

2. **Integration tests**
   - Multiple primitives combined
   - Real-world scenarios
   - Complex expressions

3. **Performance benchmarks** (future)
   - Fibonacci(30) time
   - Factorial(1000) time
   - List operations on 10k elements

---

## Implementation Plan

### Step 1: Run Consistency Audit (45 min)

```bash
cd bootstrap/bootstrap

# 1. Check all primitives are accessible
./guage << 'EOF'
(âŒ‚ (âŒœ âŠ•))
(âŒ‚ (âŒœ âŠ–))
(âŒ‚ (âŒœ âŠ—))
; ... all 55 primitives
EOF

# 2. Check error handling patterns
grep -A5 "cell_error" primitives.c > audit_errors.txt

# 3. Check reference counting
grep -E "(retain|release)" primitives.c | wc -l

# 4. Document findings
```

**Output:** CONSISTENCY_AUDIT.md

### Step 2: Run Correctness Audit (1 hour)

```bash
# Create comprehensive correctness test
cat > tests/comprehensive_correctness.test << 'EOF'
; Test all 55 functional primitives
; Arithmetic
(âŠ• #5 #3)
(âŠ– #10 #3)
; ... etc
EOF

# Run test
./guage < tests/comprehensive_correctness.test

# Create edge case test
cat > tests/edge_cases.test << 'EOF'
; Test edge cases
(âŠ˜ #5 #0)  ; Should error
; ... etc
EOF

./guage < tests/edge_cases.test
```

**Output:** CORRECTNESS_AUDIT.md

### Step 3: Run Completeness Audit (1 hour)

```bash
# Check SPEC.md against primitives.c
diff <(grep "Symbol.*Type.*Meaning" SPEC.md) \
     <(grep "prim_" primitives.c | cut -d_ -f2)

# List missing features
cat > COMPLETENESS_AUDIT.md << 'EOF'
# Completeness Audit

## Missing Features
1. âŒ (eval) - HIGH PRIORITY
2. Pattern matching - NEXT
...
EOF
```

**Output:** COMPLETENESS_AUDIT.md

### Step 4: Create Action Plan (30 min)

Based on audit results:

1. **Critical fixes** (if any)
2. **Priority features** (eval, pattern matching)
3. **Documentation updates**
4. **Timeline for Week 3**

**Output:** WEEK_3_ROADMAP.md

---

## Deliverables

### Documentation

1. **CONSISTENCY_AUDIT.md** - Audit results
2. **CORRECTNESS_AUDIT.md** - Test results
3. **COMPLETENESS_AUDIT.md** - Gap analysis
4. **WEEK_3_ROADMAP.md** - Next steps
5. **SESSION_HANDOFF.md** - Updated for Day 13

### Tests

1. **tests/comprehensive_correctness.test** - All primitives
2. **tests/edge_cases.test** - Boundary conditions
3. **tests/integration.test** - Combined primitives

### Code

1. **Any critical fixes** - Only if audit reveals bugs
2. **No new features** - Focus is audit only

---

## Success Criteria

### Must Have âœ…

- [ ] All 55 functional primitives audited
- [ ] Consistency issues documented
- [ ] Correctness verified or issues logged
- [ ] Completeness gaps identified
- [ ] Week 3 roadmap created

### Should Have ğŸ“‹

- [ ] All audit docs complete
- [ ] Critical bugs fixed (if any)
- [ ] Test coverage improved
- [ ] Documentation updated

### Nice to Have ğŸ¯

- [ ] Performance baselines
- [ ] Integration test suite
- [ ] Automated audit script

---

## Risk Assessment

### Low Risk âœ…

- Audit is non-invasive
- No breaking changes
- Clear methodology
- Well-documented system

### Medium Risk âš ï¸

- Might discover unexpected bugs
- Documentation might need major updates
- Test automation blocked by missing eval

### Mitigation

1. **Document, don't fix immediately** - Log issues for later
2. **Prioritize critical bugs only** - Don't get sidetracked
3. **Time-box each phase** - Don't over-optimize
4. **Focus on Week 3 prep** - Next phase is pattern matching

---

## Next Steps After Day 13

### Immediate (Day 14)

1. **Implement âŒ (eval)** - CRITICAL
   - Enable automatic test execution
   - Foundation for REPL
   - Required for metaprogramming

2. **Document tests-as-data design**
   - Create TESTS_AS_DATA.md
   - Explain philosophy
   - Show manual verification

3. **Create manual verification guide**
   - MANUAL_VERIFICATION_GUIDE.md
   - How to verify auto-generated tests
   - Examples for each category

### Week 3 (Days 15-21)

1. **Pattern Matching** (5 days)
   - âˆ‡ (match) primitive
   - Pattern syntax
   - Exhaustiveness checking

2. **Standard Library Basics** (2 days)
   - map, filter, fold
   - list utilities
   - Examples and tests

### Week 4+

- Macro system
- Module system
- I/O primitives
- Strings

---

## Time Allocation

| Phase | Task | Time |
|-------|------|------|
| 1 | Consistency Audit | 45 min |
| 2 | Correctness Audit | 1 hour |
| 3 | Completeness Audit | 1 hour |
| 4 | Create Action Plan | 30 min |
| | **Total** | **~3.5 hours** |

---

## Conclusion

Day 13 is about **solidifying the foundation** before moving to Week 3. We're not adding features - we're ensuring what we have is:

1. **Consistent** - All primitives follow same patterns
2. **Correct** - All primitives work as specified
3. **Complete** - All planned Day 12 work is done

After Day 13, we'll be ready for:
- **Eval implementation** (Day 14)
- **Pattern matching** (Week 3)
- **Production use** (Phase 3+)

**Status:** Ready to begin Day 13 audit
**Priority:** HIGH - Foundation must be solid
**Timeline:** ~3.5 hours
**Goal:** Production-ready base for Week 3

---

**Prepared by:** Claude Sonnet 4.5
**Date:** 2026-01-27
**Session:** Day 13 Planning
